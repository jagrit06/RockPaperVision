[{"/home/jagrit/Desktop/rpv/src/index.js":"1","/home/jagrit/Desktop/rpv/src/App.js":"2","/home/jagrit/Desktop/rpv/src/reportWebVitals.js":"3","/home/jagrit/Desktop/rpv/src/utilities.js":"4","/home/jagrit/Desktop/rpv/src/customGestures/index.js":"5","/home/jagrit/Desktop/rpv/src/customGestures/Rock.js":"6","/home/jagrit/Desktop/rpv/src/customGestures/Paper.js":"7","/home/jagrit/Desktop/rpv/src/customGestures/Scissors.js":"8"},{"size":500,"mtime":1610736206396,"results":"9","hashOfConfig":"10"},{"size":4044,"mtime":1610741286481,"results":"11","hashOfConfig":"10"},{"size":362,"mtime":1610736206396,"results":"12","hashOfConfig":"10"},{"size":2498,"mtime":1610737191022,"results":"13","hashOfConfig":"10"},{"size":173,"mtime":1610740143678,"results":"14","hashOfConfig":"10"},{"size":715,"mtime":1610740257761,"results":"15","hashOfConfig":"10"},{"size":738,"mtime":1610741367594,"results":"16","hashOfConfig":"10"},{"size":1902,"mtime":1610739582471,"results":"17","hashOfConfig":"10"},{"filePath":"18","messages":"19","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"20"},"14vg9pr",{"filePath":"21","messages":"22","errorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"23","usedDeprecatedRules":"20"},{"filePath":"24","messages":"25","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"20"},{"filePath":"26","messages":"27","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"20"},{"filePath":"28","messages":"29","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"20"},{"filePath":"30","messages":"31","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"20"},{"filePath":"32","messages":"33","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"20"},{"filePath":"34","messages":"35","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"36"},"/home/jagrit/Desktop/rpv/src/index.js",[],["37","38"],"/home/jagrit/Desktop/rpv/src/App.js",["39","40","41"],"// The following code is based heavily from the following tutroial: https://github.com/nicknochnack/GestureRecognition\n\nimport React, { useRef, useState, useEffect } from \"react\";\n\n// import logo from './logo.svg';\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as handpose from \"@tensorflow-models/handpose\";\nimport Webcam from \"react-webcam\";\nimport \"./App.css\";\nimport { drawHand } from \"./utilities\";\nimport * as fp from \"fingerpose\";\n\nimport * as customGesture from \"./customGestures\"\nimport rock from \"./rock.png\";\nimport paper from \"./paper.png\";\nimport scissors from \"./scissors.png\";\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  const [emoji, setEmoji] = useState(null);\n  const images = { rock: rock, paper: paper, scissors: scissors };\n\n  const runHandpose = async () => {\n    const net = await handpose.load();\n    console.log(\"Handpose model loaded.\");\n    //  Loop and detect hands\n    setInterval(() => {\n      detect(net);\n    }, 10);\n  };\n\n  const detect = async (net) => {\n    // Check data is available\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      // Set canvas height and width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      // Make Detections\n      const hand = await net.estimateHands(video);\n      // console.log(hand);\n\n      // Gesture Handling\n\n      if (hand.length > 0) {\n        const GE = new fp.GestureEstimator([\n          customGesture.RockGesture,\n          customGesture.PaperGesture,\n          customGesture.ScissorsGesture,\n        ]);\n        const gesture = await GE.estimate(hand[0].landmarks, 4);\n        if (gesture.gestures !== undefined && gesture.gestures.length > 0) {\n          // console.log(gesture.gestures);\n\n          const confidence = gesture.gestures.map(\n            (prediction) => prediction.confidence\n          );\n          const maxConfidence = confidence.indexOf(\n            Math.max.apply(null, confidence)\n          );\n          // console.log(gesture.gestures[maxConfidence].name);\n          setEmoji(gesture.gestures[maxConfidence].name);\n          console.log(emoji);\n        }\n      }\n\n      ///////// NEW STUFF ADDED GESTURE HANDLING\n\n      // Draw mesh\n      const ctx = canvasRef.current.getContext(\"2d\");\n      drawHand(hand, ctx);\n    }\n  };\n\n  useEffect(()=>{runHandpose()},[]);\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <Webcam\n          ref={webcamRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 600,\n            right: 0,\n            bottom: 100,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n\n        <canvas\n          ref={canvasRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 600,\n            right: 0,\n            bottom: 100,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n        {emoji !== null ? (\n          <img\n            src={images[emoji]}\n            style={{\n              position: \"absolute\",\n              marginLeft: \"auto\",\n              marginRight: \"auto\",\n              left: 1000,\n              bottom: 600,\n              right: 0,\n              textAlign: \"center\",\n              height: 100,\n            }}\n          />\n        ) : (\n          \"\"\n        )}\n      </header>\n    </div>\n  );\n}\n\nexport default App;","/home/jagrit/Desktop/rpv/src/reportWebVitals.js",[],"/home/jagrit/Desktop/rpv/src/utilities.js",[],"/home/jagrit/Desktop/rpv/src/customGestures/index.js",[],"/home/jagrit/Desktop/rpv/src/customGestures/Rock.js",[],"/home/jagrit/Desktop/rpv/src/customGestures/Paper.js",[],"/home/jagrit/Desktop/rpv/src/customGestures/Scissors.js",[],["42","43"],{"ruleId":"44","replacedBy":"45"},{"ruleId":"46","replacedBy":"47"},{"ruleId":"48","severity":1,"message":"49","line":6,"column":13,"nodeType":"50","messageId":"51","endLine":6,"endColumn":15},{"ruleId":"52","severity":1,"message":"53","line":90,"column":33,"nodeType":"54","endLine":90,"endColumn":35,"suggestions":"55"},{"ruleId":"56","severity":1,"message":"57","line":127,"column":11,"nodeType":"58","endLine":139,"endColumn":13},{"ruleId":"44","replacedBy":"59"},{"ruleId":"46","replacedBy":"60"},"no-native-reassign",["61"],"no-negated-in-lhs",["62"],"no-unused-vars","'tf' is defined but never used.","Identifier","unusedVar","react-hooks/exhaustive-deps","React Hook useEffect has a missing dependency: 'runHandpose'. Either include it or remove the dependency array.","ArrayExpression",["63"],"jsx-a11y/alt-text","img elements must have an alt prop, either with meaningful text, or an empty string for decorative images.","JSXOpeningElement",["61"],["62"],"no-global-assign","no-unsafe-negation",{"desc":"64","fix":"65"},"Update the dependencies array to be: [runHandpose]",{"range":"66","text":"67"},[2784,2786],"[runHandpose]"]